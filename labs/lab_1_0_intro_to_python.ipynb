{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFfPLA-2EOTu"
   },
   "source": [
    "# AI Workshop - Lab 1-0: Introduction to Python\n",
    "\n",
    "In this introductory lab, we will get hands-on experience with Python, NumPy, and scikit-learn. This lab is designed to provide you with foundational skills for working in Python notebooks and using essential libraries for data science and machine learning. If you're already comfortable with these tools, feel free to skip ahead to Lab 1: Data Cleaning and Processing.\n",
    "\n",
    "### Objectives\n",
    "- Learn to use Python in a notebook environment.\n",
    "- Get familiar with NumPy for numerical computations.\n",
    "- Understand basic scikit-learn operations for machine learning tasks.\n",
    "\n",
    "### Overview\n",
    "This lab will cover the following:\n",
    "1. **Notebook Basics**:\n",
    "   - Understand how to use notebook cells for code and text.\n",
    "   - Learn shortcuts for running and modifying cells.\n",
    "2. **NumPy Basics**:\n",
    "   - Explore NumPy arrays, indexing, slicing, and basic operations.\n",
    "   - Practice creating and manipulating multi-dimensional arrays.\n",
    "   - Use vectorized operations for efficiency.\n",
    "3. **Scikit-learn Basics**:\n",
    "   - Load and explore the iris dataset.\n",
    "   - Conduct exploratory data analysis (EDA) using visualizations.\n",
    "   - Learn about the `n_samples x n_features` format for machine learning data.\n",
    "\n",
    "### Dataset: Iris\n",
    "We will work with the famous **iris dataset**, which includes:\n",
    "- **Features**:\n",
    "  - Sepal width (cm)\n",
    "  - Sepal length (cm)\n",
    "  - Petal width (cm)\n",
    "  - Petal length (cm)\n",
    "- **Target classes**:\n",
    "  - Setosa (class 0)\n",
    "  - Versicolor (class 1)\n",
    "  - Virginica (class 2)\n",
    "\n",
    "The dataset is a great starting point for understanding basic machine learning workflows. You can learn more about it on its [Wikipedia page](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n",
    "\n",
    "An example of each iris species is shown below:\n",
    "\n",
    "<label for=\"Setosa\">Setosa</label>\n",
    "<img width=200 alt=\"Setosa\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/56/Kosaciec_szczecinkowaty_Iris_setosa.jpg\">\n",
    "\n",
    "<label for=\"Versicolor\">Versicolor</label>\n",
    "<img width=200 alt=\"Versicolor\" src=\"https://upload.wikimedia.org/wikipedia/commons/4/41/Iris_versicolor_3.jpg\">\n",
    "\n",
    "<label for=\"Virginica\">Virginica</label>\n",
    "<img width=200 alt=\"Virginica\" src=\"https://upload.wikimedia.org/wikipedia/commons/9/9f/Iris_virginica.jpg\">\n",
    "\n",
    "### Key Steps in Lab\n",
    "1. **NumPy Operations**:\n",
    "   - Create and manipulate arrays.\n",
    "   - Perform basic indexing and slicing.\n",
    "   - Use vectorized operations to compute metrics like accuracy.\n",
    "2. **EDA with Scikit-learn**:\n",
    "   - Load the iris dataset and inspect its structure.\n",
    "   - Explore features and target classes.\n",
    "   - Visualize data using matplotlib to identify patterns and relationships.\n",
    "3. **Hands-on Exercises**:\n",
    "   - Answer questions about the dataset using NumPy and scikit-learn.\n",
    "   - Practice visualizing data and interpreting patterns.\n",
    "\n",
    "### Goals\n",
    "By the end of this lab, you will:\n",
    "- Understand how to use notebooks for interactive Python development.\n",
    "- Gain proficiency in using NumPy for numerical operations.\n",
    "- Begin exploring machine learning workflows using scikit-learn.\n",
    "- Build confidence in visualizing and analyzing datasets.\n",
    "\n",
    "### Getting Started\n",
    "1. Execute code cells as instructed to observe results.\n",
    "2. Complete the \"YOUR TURN\" exercises to test your understanding.\n",
    "\n",
    "Let’s begin by exploring the notebook environment and learning how to work with Python libraries like NumPy and scikit-learn. **Run the first code cell to import the necessary libraries!**\n",
    "\n",
    "### Importing Libraries: What and Why?\n",
    "\n",
    "In Python, a **library** is a collection of pre-written code that provides tools and functionality to solve specific problems or perform common tasks, so you don’t have to write everything from scratch. By importing a library, you gain access to its functions, classes, and modules, which you can use in your own code.\n",
    "\n",
    "For example:\n",
    "- **NumPy**: This library specializes in handling large, multi-dimensional arrays and matrices. It is optimized for numerical computations and provides powerful tools for mathematical operations, making it an essential library for data science and machine learning tasks. While Python is natively equipped to handle many of the same operations as NumPy, NumPy is much more efficient and is designed for numerical operations. [Learn more](https://numpy.org/)\n",
    "- **scikit-learn**: A widely used library for machine learning. It offers tools for data preparation, model training, and evaluation. With scikit-learn, you can build models for tasks like classification, regression, and clustering with ease. [Learn more](https://scikit-learn.org/stable/)\n",
    "\n",
    "\n",
    "_Note: To run a cell on Google Colab, you can either click the Play icon to the left of the cell or use the keyboard shortcut \"Shift+Enter\"._"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFhv0y38EOTv",
    "outputId": "dfac40ee-58bb-4c1e-d5c9-9477c587659e"
   },
   "source": [
    "import sklearn\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6EJDXQ2EOTx"
   },
   "source": [
    "### NumPy Basics\n",
    "\n",
    "In Python, while you can create and manipulate lists, NumPy provides specialized tools for working with numerical data in arrays, making it faster and more efficient for large datasets.\n",
    "\n",
    "The code below demonstrates:\n",
    "1. **Creating an Array**: `np.arange(8)` generates a sequence of numbers from 0 to 7.\n",
    "2. **Reshaping the Array**: `.reshape(2, 4)` reorganizes these numbers into a 2x4 (2 rows, 4 columns) array.\n",
    "\n",
    "By running this code, you'll create a NumPy array called `array` and display it. We can then use the array to explore its properties and perform operations.\n",
    "\n",
    "**>> Run the code in the next cell to create and display the 2x4 array.**\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQxQkId8EOTx",
    "outputId": "eac95daa-2c34-4dde-8b8d-fd2e00cd9cb5"
   },
   "source": [
    "# Create a variable called \"array\" and fill it with a 2x4 NumPy array\n",
    "array = np.arange(8).reshape(2,4)\n",
    "array # Display the array"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmbEmYFPEOTz"
   },
   "source": [
    "We can access the **properties** of a NumPy array, such as its shape, number of dimensions, data type, and total number of elements, using a dot (`.`) followed by the property name.\n",
    "\n",
    "In Python, an **object** (like a NumPy array) has **attributes** and **methods**:\n",
    "- **Attributes** store information about the object, such as its shape or size. These are like \"built-in variables\" attached to the object.\n",
    "- **Methods** are functions attached to the object that perform specific actions, like reshaping the array.\n",
    "\n",
    "When accessing an attribute, you use the syntax `object.attribute`. For example:\n",
    "- `array.shape` retrieves the dimensions of the array as a tuple (rows, columns).\n",
    "- `array.ndim` retrieves the number of dimensions in the array.\n",
    "- `array.size` retrieves the total number of elements in the array.\n",
    "\n",
    "You don’t need parentheses `()` for attributes because they are not functions you’re calling—they simply hold information. In contrast, methods, like `array.reshape(2, 4)`, do require parentheses because they perform an operation.\n",
    "\n",
    "Below is an example of accessing and printing several attributes of the array:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIuwFnemEOTz",
    "outputId": "9fad6c3e-f102-4738-ff8f-908da5b4364a"
   },
   "source": [
    "print(\"Shape:\", array.shape)              # Tuple representing the array dimensions\n",
    "print(\"Dimensions:\", array.ndim)          # Number of dimensions (e.g., 2 for a 2D array)\n",
    "print(\"Data type:\", array.dtype)          # Type of elements stored in the array (e.g., int64)\n",
    "print(\"Number of elements:\", array.size)  # Total number of elements in the array"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-y0kkdeEOT0"
   },
   "source": "If we have a **Python list** (an ordered collection of elements), we can easily convert it into a NumPy array using the `np.array()` function. This is useful because NumPy arrays are more efficient and provide additional functionality compared to standard Python lists."
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MTl7XGG2EOT1",
    "outputId": "1b592f1b-1d85-4684-de6c-f746b945cd15"
   },
   "source": [
    "mylist = [0, 1, 1, 2, 3, 5, 8, 13, 21]  # A Python list\n",
    "myarray = np.array(mylist)              # Convert the list to a NumPy array\n",
    "myarray                                 # Displays the array"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qz0g0_mYEOT2"
   },
   "source": "We can also work with **nested lists** (lists of lists) to create multidimensional NumPy arrays. Each nested list becomes a row in the resulting array, allowing us to represent tabular data or matrices. For example:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NAZUXTYcEOT2",
    "outputId": "8293931a-bc10-461a-e557-a7c554375a38"
   },
   "source": [
    "my2dlist = [[1, 2, 3], [4, 5, 6]]  # A nested list\n",
    "my2darray = np.array(my2dlist)     # Convert it into a 2D NumPy array\n",
    "my2darray                          # Displays the array"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1bkuyDAEOT3"
   },
   "source": [
    "### Indexing and Slicing NumPy Arrays\n",
    "\n",
    "Indexing and slicing allow you to access specific parts of a NumPy array. These operations are essential for extracting and working with subsets of data.\n",
    "\n",
    "- **Indexing**: Refers to accessing individual elements of an array by their position (index). In Python, indexing starts at 0, so the first element is at index `0`, the second at index `1`, and so on.\n",
    "- **Slicing**: Refers to extracting a range of elements from an array. This is done using the colon (`:`) operator, which specifies a start, stop, and step size. For example, `array[start:stop]` will extract elements starting at `start` and stopping before `stop`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnZjmyCqEOT3",
    "outputId": "db7d0be3-8cc7-4363-f570-b3b69bbf0219"
   },
   "source": [
    "array = np.arange(10)                               # Create an array with numbers 0 through 9\n",
    "print(\"Originally:\", array)                         # Print the entire array\n",
    "print(\"First four elements:\", array[:4])            # Slice: first 4 elements (indices 0 to 3)\n",
    "print(\"After the first four elements:\", array[4:])  # Slice: from index 4 to the end\n",
    "print(\"The last element:\", array[-1])               # Indexing: access the last element"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lp6nck2REOT4"
   },
   "source": [
    "And we can index/slice multidimensional arrays, too."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdLxn49WEOT4",
    "outputId": "09f0e7d5-9e95-4bd7-bfa9-5258e81279da"
   },
   "source": [
    "array = np.array([[1,2,3],[4,5,6]])\n",
    "print (\"Originally: \", array)\n",
    "print (\"First row only: \", array[0])\n",
    "print (\"First column only: \", array[:,0])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQYx2QXiEOT5"
   },
   "source": [
    "#### Sneak Preview: Computing Accuracy with NumPy\n",
    "\n",
    "In machine learning, a common task is to evaluate the performance of a classifier by comparing its **predictions** to the **true values** (or ground truth). One way to measure this is by calculating the classifier's **accuracy**, which is the proportion of correct predictions.\n",
    "\n",
    "Accuracy is computed as:\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}\n",
    "$$\n",
    "\n",
    "In this example:\n",
    "- `true_values` represents the ground truth labels for a dataset (0 = negative class, 1 = positive class).\n",
    "- `predictions` represents the corresponding labels predicted by a machine learning model.\n",
    "\n",
    "Using NumPy, we can:\n",
    "1. **Convert Lists to Arrays**: First, we convert the Python lists into NumPy arrays for efficient element-wise operations.\n",
    "2. **Compare Arrays Element-wise**: `true_values_array == predictions_array` returns a Boolean array where `True` indicates matching elements.\n",
    "3. **Count Correct Predictions**: `np.sum()` sums the `True` values (treated as `1` in NumPy) to get the total number of correct predictions.\n",
    "4. **Divide by Total Elements**: To calculate accuracy, divide the number of correct predictions by the total number of elements in the array, given by `.size`.\n",
    "\n",
    "Here’s the code:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_rzMxsmLEOT5",
    "outputId": "5c6c88c0-42de-457a-b99a-650087761b36"
   },
   "source": [
    "true_values = [0, 0, 1, 1, 1, 1, 1, 0, 1, 0]  # Ground truth labels\n",
    "predictions = [0, 0, 0, 1, 1, 1, 0, 1, 1, 0]  # Predicted labels\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "true_values_array = np.array(true_values)\n",
    "predictions_array = np.array(predictions)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = np.sum(true_values_array == predictions_array) / true_values_array.size\n",
    "print(\"Accuracy:\", accuracy * 100, \"%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmNWbLweEOT6"
   },
   "source": [
    "### Scikit-learn Basics\n",
    "\n",
    "Scikit-learn is a powerful Python library for building and evaluating machine learning models. It provides tools for a wide range of tasks, including:\n",
    "- Data preparation\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Classification and regression\n",
    "- Clustering and more\n",
    "\n",
    "One key aspect of scikit-learn is that it expects data to be structured as a **2D matrix**, where:\n",
    "- Rows represent individual **samples** (*n_samples*), like data points or observations.\n",
    "- Columns represent **features** (*n_features*), which are the characteristics or measurements of the samples.\n",
    "The model also requires a separate column for the **target**, which contains the values you’re trying to predict (e.g., labels for classification tasks).\n",
    "\n",
    "To get started with scikit-learn, we’ll use the famous **iris dataset**, which is a small and straightforward dataset commonly used for teaching and testing machine learning algorithms.\n",
    "\n",
    "#### About the Iris Dataset\n",
    "Each entry in the dataset represents a type of iris plant, categorized into one of three **classes** (targets):\n",
    "- **Setosa** (class 0)\n",
    "- **Versicolor** (class 1)\n",
    "- **Virginica** (class 2)\n",
    "\n",
    "Each iris sample includes the following **features**:\n",
    "- Sepal width (cm)\n",
    "- Sepal length (cm)\n",
    "- Petal width (cm)\n",
    "- Petal length (cm)\n",
    "\n",
    "These features describe the physical characteristics of the plant, and the task is to use them to predict the correct class of iris."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g2-wyZx6EOT6"
   },
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_data = load_iris()\n",
    "feature_data = iris_data.data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tr3OodXEEOT6"
   },
   "source": [
    "**YOUR TURN:**\n",
    "The variable `feature_data` now contains the feature data for all the iris samples. Use the attributes of the NumPy array to answer the following questions:\n",
    "\n",
    "1. What is the shape of this feature data?\n",
    "2. What is the data type?\n",
    "3. How many samples are there?\n",
    "4. How many features are there?\n",
    "\n",
    "**Hints**:\n",
    "- Remember, **attributes** are accessed using a dot (`.`) followed by the attribute name (e.g., `array.shape`). They do not require parentheses because they are not methods.\n",
    "- Use the `.shape` attribute to find both the number of samples (rows) and the number of features (columns).\n",
    "- Use the `.dtype` attribute to determine the type of data stored in the array.\n",
    "- For additional help or details about an attribute or method, you can use the `help()` function in Python (e.g., `help(array.shape)`).\n",
    "\n",
    "Write your code in the cell below and run it to find the answers!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGSb93AUEOT7",
    "outputId": "b7b1f98e-5483-4040-ba35-a9afb98b43c9"
   },
   "source": "# Your Code Here",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADPK_IktEOT7"
   },
   "source": [
    "Next, we need to extract the **target data**, which represents the class labels for each sample in the dataset (e.g., Setosa, Versicolor, or Virginica). These labels indicate the category each iris sample belongs to and will be used as the ground truth for model training and evaluation.\n",
    "\n",
    "In addition to the numerical labels (e.g., 0, 1, 2), we’ll also retrieve the **target names**, which provide the human-readable class names (e.g., \"Setosa\"). This will help us interpret the results later.\n",
    "\n",
    "Run the code below to extract and save:\n",
    "- `target_data`: The numeric class labels for each sample.\n",
    "- `target_names`: The class names corresponding to the numeric labels."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "txwjzkomEOT7"
   },
   "source": [
    "target_data = iris_data.target       # Numeric class labels (0, 1, 2)\n",
    "target_names = iris_data.target_names  # Human-readable class names (\"Setosa\", etc.)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNjpq5XcEOT8"
   },
   "source": [
    "**YOUR TURN:**\n",
    "Now that you’ve extracted the `target_data` and `target_names`, use them to answer the following questions:\n",
    "\n",
    "1. What values are in `target_data`?\n",
    "2. What is the data type of `target_data`?\n",
    "3. What values are in `target_names`?\n",
    "4. What is the data type of `target_names`?\n",
    "5. How many samples are of type \"setosa\"?\n",
    "\n",
    "**Hints**:\n",
    "- To see the contents of `target_data` or `target_names`, simply print them or type their variable names in a cell.\n",
    "- Use the `.dtype` attribute to find the data type of each variable (e.g., numeric or string).\n",
    "- To count how many samples are of type \"setosa\":\n",
    "  - Remember, the numeric label for \"setosa\" can be found in `target_names` (usually 0).\n",
    "  - Use a Boolean condition with `np.sum()` to count occurrences (e.g., `np.sum(target_data == 0)`).\n",
    "- If you’re unsure about the structure or properties of these variables, you can always use `type()` or `dir()` to explore them further."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qbk1mRqYEOT8",
    "outputId": "cb768dbe-3ca7-4e0e-85e2-acaaf24bfc32"
   },
   "source": "# Your Code Here",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZkEii2tEOT8"
   },
   "source": [
    "### Visual EDA: Exploring Feature Relationships\n",
    "\n",
    "To better understand the dataset, we can perform **visual exploratory data analysis (EDA)** by plotting the samples based on a subset of their features. This helps us identify patterns or relationships between the features and the target classes.\n",
    "\n",
    "In this example, we’ll use **matplotlib**, a popular Python library for data visualization, to create a scatter plot of **sepal width** versus **sepal length**. Each data point will be color-coded to represent its target class (Setosa, Versicolor, or Virginica). [Learn more about matplotlib](https://matplotlib.org/)\n",
    "\n",
    "#### Steps:\n",
    "1. **Group Data by Class**:\n",
    "   - Filter `feature_data` using Boolean indexing based on the `target_data` values to separate the samples into three groups: `setosa`, `versicolor`, and `virginica`.\n",
    "2. **Create the Plot**:\n",
    "   - Use `plt.scatter()` to plot each group with its respective features and a unique label.\n",
    "3. **Add Labels and a Legend**:\n",
    "   - Add axis labels, a title, and a legend to make the plot informative.\n",
    "\n",
    "Run the code below to generate the plot:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "yctO8uMCEOT9",
    "outputId": "8cb50903-b2d4-4a13-8c4a-ce55f299ebec"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group samples by class\n",
    "setosa = feature_data[target_data == 0]\n",
    "versicolor = feature_data[target_data == 1]\n",
    "virginica = feature_data[target_data == 2]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(setosa[:, 0], setosa[:, 1], label=\"setosa\")\n",
    "plt.scatter(versicolor[:, 0], versicolor[:, 1], label=\"versicolor\")\n",
    "plt.scatter(virginica[:, 0], virginica[:, 1], label=\"virginica\")\n",
    "\n",
    "# Add labels and legend\n",
    "plt.legend()\n",
    "plt.xlabel(\"sepal length (cm)\")\n",
    "plt.ylabel(\"sepal width (cm)\")\n",
    "plt.title(\"Visual EDA\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZruiACNEOT9"
   },
   "source": [
    "In the previous step, we used **Boolean indexing** to filter the feature data for each class based on the `target_data`. This allowed us to create a scatter plot where the iris classes were color-coded, making it easier to observe patterns and relationships between sepal length and sepal width.\n",
    "\n",
    "### Observations:\n",
    "- The \"Setosa\" class is typically distinguishable with medium-to-high sepal width and low-to-medium sepal length, making it visually separable from the other two classes.\n",
    "- The \"Versicolor\" and \"Virginica\" classes overlap significantly in this feature space, making them harder to distinguish.\n",
    "\n",
    "**YOUR TURN:**\n",
    "Answer the following questions based on the scatter plot:\n",
    "1. Which of the iris classes is clearly separable based on sepal characteristics?\n",
    "2. Which of the iris classes overlap and are not easily separable?\n",
    "3. Is it possible to visualize all the features for all samples in a single 2D plot? Why or why not?\n",
    "\n",
    "**Hints**:\n",
    "- For question 3, consider that the dataset has **four features** (sepal length, sepal width, petal length, and petal width), but a 2D plot can only display two at a time. Think about whether all relationships and patterns could fit into a single 2D plot.\n",
    "- If unsure, explore higher-dimensional visualizations or transformations like PCA (principal component analysis), which will be covered in later labs.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "In this lab, we explored the foundational tools and concepts necessary for working with Python, NumPy, and scikit-learn in the context of machine learning and data analysis. Here’s a summary of what we covered:\n",
    "\n",
    "1. **Python and Libraries**:\n",
    "   - Learned the basics of importing and using libraries like NumPy and scikit-learn to streamline numerical and machine learning tasks.\n",
    "2. **NumPy Fundamentals**:\n",
    "   - Worked with arrays, explored their properties, and performed indexing, slicing, and vectorized operations for efficient data manipulation.\n",
    "3. **Exploratory Data Analysis (EDA)**:\n",
    "   - Loaded and inspected the iris dataset, visualized feature relationships using scatter plots, and analyzed patterns in the data.\n",
    "4. **Scikit-learn Basics**:\n",
    "   - Understood how machine learning datasets are structured and prepared, focusing on the `n_samples x n_features` format.\n",
    "   - Explored class labels (targets) and their relationship to the feature data.\n",
    "\n",
    "### Key Takeaways:\n",
    "- NumPy and scikit-learn are essential tools for data science and machine learning, offering powerful abstractions for handling data and building models.\n",
    "- Visual EDA provides critical insights into feature relationships and class separability, which inform model design.\n",
    "- The iris dataset, while small, is an excellent starting point for learning about classification tasks and machine learning workflows.\n",
    "\n",
    "As we move forward in this workshop, we’ll build on these foundational skills to:\n",
    "- Dive deeper into data cleaning and preprocessing.\n",
    "- Design and evaluate machine learning models using real-world datasets.\n",
    "- Explore advanced techniques for feature engineering, model optimization, and interpretability.\n",
    "\n",
    "Take some time to review the concepts and experiment with the provided code. When you're ready, proceed to **Lab 1: Data Cleaning and Processing**, where we’ll focus on preparing raw data for machine learning.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "lab-1-1-basics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
