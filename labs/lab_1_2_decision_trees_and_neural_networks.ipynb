{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SF0pPVB4-LHp"
   },
   "source": [
    "# AI Workshop - Lab 2-1: Decision Trees and Neural Networks\n",
    "\n",
    "In this lab, we will build on concepts introduced earlier by diving deeper into two powerful machine learning techniques: **decision trees** and **neural networks**. We'll explore their strengths, limitations, and practical applications using real-world datasets.\n",
    "\n",
    "### Objectives\n",
    "- Understand how decision trees work and how to interpret their outputs.\n",
    "- Use decision trees to classify weather data and predict cloud presence.\n",
    "- Explore feature importances and visualize decision tree structures.\n",
    "- Build and train a feedforward neural network using Keras for a regression task.\n",
    "- Compare the performance and usability of these methods for different tasks.\n",
    "\n",
    "### Data Overview\n",
    "We will continue using the **energy and weather datasets**, which contain information about power generation and weather observations. These datasets include features like energy generation by source (e.g., solar, nuclear, wind) and weather conditions (e.g., temperature, humidity, cloud cover).\n",
    "\n",
    "#### Highlights of the Data:\n",
    "- The target variable for decision trees will be **cloud presence**, determined from the `clouds_all` column.\n",
    "- For the neural network regression task, the target variable will be **total energy consumption** (`total load actual`), predicted based on weather conditions.\n",
    "\n",
    "### Key Steps in Lab\n",
    "1. **Decision Trees**:\n",
    "   - Learn the basics of decision trees and their practical use cases.\n",
    "   - Train a decision tree classifier to predict cloud presence based on energy generation data.\n",
    "   - Explore feature importances and visualize the trained decision tree.\n",
    "   - Experiment with hyperparameter tuning using Grid Search and cross-validation.\n",
    "\n",
    "2. **Neural Networks**:\n",
    "   - Prepare the data for a regression task by encoding categorical variables, imputing missing values, and scaling features.\n",
    "   - Build and train a simple feedforward neural network using Keras.\n",
    "   - Evaluate the model's performance on the test set using metrics such as Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE).\n",
    "\n",
    "### Goals\n",
    "By the end of this lab, you will:\n",
    "- Understand how decision trees make predictions and how to interpret their visual representations.\n",
    "- Gain hands-on experience with hyperparameter tuning and feature importance analysis.\n",
    "- Learn how to design and train a simple neural network for regression tasks.\n",
    "- Understand the trade-offs between decision trees and neural networks for different types of machine learning problems.\n",
    "\n",
    "Let’s begin by exploring decision trees and their application to predicting cloud cover using the weather and energy datasets!\n",
    "\n",
    "### Decision Trees\n",
    "\n",
    "Decision trees are a type of supervised learning algorithm used for both **classification** and **regression** tasks. They work by splitting the dataset into smaller and smaller subsets based on simple decision rules, eventually making predictions at the \"leaves\" of the tree.\n",
    "\n",
    "#### Why Use Decision Trees?\n",
    "- **Easy to Understand**: They are intuitive and can be visualized as flowcharts, making them ideal for explaining decisions to others.\n",
    "- **Minimal Data Preparation**: Unlike some models, decision trees don’t require feature scaling or normalization.\n",
    "- **Interpretability**: Trained decision trees are not \"black boxes\" and can be analyzed to understand the decision-making process.\n",
    "\n",
    "#### Example: Deciding Whether to Buy a Used Car\n",
    "Consider a decision tree like the one below that predicts whether you should buy a used car. The decisions are based on features such as road testing, mileage, and the car's year or model.\n",
    "\n",
    "<img src=\"https://github.com/lyeskhalil/mlbootcamp/blob/master/img/decision-tree.gif?raw=1\" width=\"500\"/>\n",
    "\n",
    "**YOUR TURN:**\n",
    "1. According to the decision tree, should you buy a car that has been road tested, has high mileage, and is a recent year/model? ____________________________\n",
    "2. Will your model recommend buying any cars that haven't been road tested? ____________________________\n",
    "\n",
    "While decision trees are simple and interpretable, they aren’t always perfect. For example, the above tree might suggest buying a road-tested car with a recent year but extremely high mileage—something you may want to avoid in reality. These nuances highlight the importance of feature selection and fine-tuning when designing decision trees.\n",
    "\n",
    "---\n",
    "\n",
    "### Energy and Weather Datasets\n",
    "\n",
    "To practice decision trees in this lab, we’ll use **energy and weather datasets** as in the previous lab. These datasets contain features such as weather conditions and electricity demand, allowing us to explore how decision trees can predict energy usage based on environmental factors.\n",
    "\n",
    "To save time, we’ve prepared a cleaned version of the data. Run the following code to load the dataset and take a quick look at its structure:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mDl1JKwx-LHx",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "outputId": "568c744b-f3f1-4a88-fa1c-8b4be9a2bbd2"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned energy data\n",
    "df = pd.read_csv('https://github.com/alexwolson/mdlw_materials/raw/refs/heads/main/data/cleaned_energy_weather.csv.gz')\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "BRObUOh0MwVk"
   },
   "cell_type": "markdown",
   "source": [
    "Pandas makes it easy to summarize and understand datasets quickly. One of the most useful tools for this is the `.describe()` method, which provides a statistical summary of the numerical columns in the dataset.\n",
    "\n",
    "This statistical overview helps you:\n",
    "\n",
    "- Understand the range and distribution of values in the dataset.\n",
    "- Spot any potential anomalies, like extremely high or low values.\n",
    "- Identify columns that might need further cleaning or transformation.\n",
    "\n",
    "Use this summary as a first step to gain insights into the dataset before applying machine learning models or deeper analysis."
   ]
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "uVAoK4nNMwVl",
    "outputId": "1d16d4c0-af71-4b96-bff5-cf97389bc260"
   },
   "cell_type": "code",
   "source": [
    "df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-a-uiu0-LH3"
   },
   "source": [
    "### Model Development: Predicting Cloud Cover\n",
    "\n",
    "In the previous lab, we explored predicting weather conditions based on energy demand. However, the large number of weather condition types made it challenging to achieve accurate predictions. By reducing the problem to a binary task, we can focus on building and evaluating a straightforward model.\n",
    "\n",
    "In this lab, we’ll focus on building a model to predict the **presence or absence of clouds** using the `clouds_all` column in the dataset. This column records the percentage of cloud cover at the time of observation. We will simplify the task into a binary classification problem:\n",
    "- **1 (True)**: Cloud cover is present (`clouds_all != 0`).\n",
    "- **0 (False)**: No cloud cover (`clouds_all == 0`).\n",
    "\n",
    "#### Steps to Prepare the Data:\n",
    "1. **Define the Target**:\n",
    "   - The `target_data` will be a binary representation of cloud cover: `True` for presence and `False` for absence.\n",
    "2. **Select Features**:\n",
    "   - We use columns related to energy generation (e.g., `generation solar`, `generation wind onshore`) as the input features. These features may correlate with cloud cover.\n",
    "3. **Split the Data**:\n",
    "   - Using `train_test_split` from scikit-learn, split the dataset into training and testing sets:\n",
    "     - **Training Set**: Used to train the model.\n",
    "     - **Testing Set**: Used to evaluate how well the model generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uXuxpDkP-LH3"
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Define the target (presence of clouds)\n",
    "target_data = df['clouds_all'] != 0  # Binary classification: True (clouds present), False (no clouds)\n",
    "\n",
    "# Define features (energy generation columns)\n",
    "feature_data = df[['generation biomass', 'generation fossil brown coal/lignite',\n",
    "                   'generation fossil gas',\n",
    "                   'generation fossil hard coal', 'generation fossil oil',\n",
    "                   'generation hydro pumped storage consumption',\n",
    "                   'generation hydro run-of-river and poundage',\n",
    "                   'generation hydro water reservoir',\n",
    "                   'generation nuclear', 'generation other', 'generation other renewable',\n",
    "                   'generation solar', 'generation waste',\n",
    "                   'generation wind onshore']]\n",
    "\n",
    "# Split data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, target_data, test_size=0.3, random_state=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4U5WwH2-LH4"
   },
   "source": [
    "**YOUR TURN:**\n",
    "Using the data split above, answer the following questions about the training and test sets:\n",
    "\n",
    "1. How many samples are in the training set? _______________________\n",
    "2. How many samples are in the test set? _______________________\n",
    "3. What percentage of the samples in the training set have clouds? _______________________\n",
    "\n",
    "**Hints:**\n",
    "- To find the number of samples in the training and test sets, use the `.shape` attribute on `X_train` and `X_test` (e.g., `X_train.shape[0]` gives the number of rows).\n",
    "- To calculate the percentage of samples with clouds in the training set:\n",
    "  - Use a Boolean condition to filter `y_train` for `True` values (e.g., `np.sum(y_train)` since `True` is treated as 1).\n",
    "  - Divide the count of samples with clouds by the total number of samples in `y_train` and multiply by 100 for the percentage."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ANVOauwm-LH4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d4716864-c617-461a-df87-c5c4b84c25ed"
   },
   "source": "# Your Code Here",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZp4c8Hg-LH5"
   },
   "source": [
    "Before fitting our decision tree model, we need to handle any **missing values** in our dataset. This time, instead of manually replacing missing values as we did in the previous lab, we’ll use the `SimpleImputer` class from scikit-learn. This makes the process more efficient and consistent.\n",
    "\n",
    "#### What We'll Do:\n",
    "1. Create a `SimpleImputer` instance configured to use the **most frequent** value as the replacement strategy.\n",
    "2. Fit the imputer on the training data to calculate the replacement values.\n",
    "3. Transform the training data to replace any missing values with these calculated values.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fQFGk9hk-LH5"
   },
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Initialize the SimpleImputer with the 'most_frequent' strategy\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "# Fit the imputer on the training data\n",
    "imp.fit(X_train)\n",
    "\n",
    "# Replace missing values in the training data\n",
    "X_train = imp.transform(X_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqj-hPeg-LH6"
   },
   "source": [
    "Now that we’ve prepared the data, we’re ready to train a decision tree classifier on our training data. By fitting the model, we allow it to learn the relationships between the input features (`X_train`) and the target (`y_train`).\n",
    "\n",
    "We set the `max_depth` of the tree to **10**, not only to reduce the risk of overfitting but also to ensure the tree is small enough for us to visualize and understand what it’s doing. A deeper tree could become too complex to interpret effectively, making it harder to analyze the model’s decision-making process.\n",
    "\n",
    "#### What Are We Doing?\n",
    "1. **Initialize the Classifier**:\n",
    "   - We use `tree.DecisionTreeClassifier` from scikit-learn to create a decision tree with a maximum depth of 10.\n",
    "2. **Train the Model**:\n",
    "   - Use the `.fit()` method to train the decision tree on `X_train` and `y_train`.\n",
    "3. **Evaluate Training Accuracy**:\n",
    "   - Compute the training accuracy by comparing the model’s predictions (`clf.predict(X_train)`) with the actual labels (`y_train`).\n",
    "   - Use the `accuracy_score` function to calculate the percentage of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VqxAAXVU-LH6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5f0e54fe-3e32-4fde-84fa-3bc614604ca4"
   },
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "# Initialize the decision tree classifier with a max depth of 10\n",
    "clf = tree.DecisionTreeClassifier(max_depth=10)\n",
    "\n",
    "# Fit the model to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate training accuracy\n",
    "accuracy = accuracy_score(y_train, clf.predict(X_train))\n",
    "print(\"Training Accuracy:\", accuracy * 100, \"%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1yMNmyr-LH6"
   },
   "source": [
    "In the previous cell, we defined and trained a **Decision Tree classifier** on our training data. When we used it to predict on the same training set, we achieved an accuracy of approximately **63%**.\n",
    "\n",
    "**YOUR TURN:**\n",
    "1. **Why didn’t the decision tree achieve 100% accuracy on the training set?**\n",
    "   - Think about the nature of the data and the limitations of decision trees.\n",
    "\n",
    "2. **What is the performance of this model on the test set?**\n",
    "   - To evaluate the model’s generalization ability, use the test set. You can calculate the accuracy on the test set using the same approach as above."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F4vftzMR-LH7"
   },
   "source": [
    "# Evaluate the model on the test set\n",
    "test_accuracy = accuracy_score(y_test, clf.predict(X_test))\n",
    "print(\"Test Accuracy:\", test_accuracy * 100, \"%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4KZ5J-t-LH7"
   },
   "source": [
    "One advantage of decision trees is that they provide insights into the **importance of each feature** in predicting the target variable. The feature importance represents how much a particular feature contributes to reducing impurity (e.g., uncertainty or misclassification) in the tree's splits. The tree assigns higher importance to features that help it make better splits.\n",
    "\n",
    "#### How It Works:\n",
    "1. **Evaluate Each Split**:\n",
    "   - At each decision node, the algorithm selects the feature that reduces impurity the most (e.g., makes the classes in a node more similar).\n",
    "\n",
    "2. **Track Contribution**:\n",
    "   - The improvement in impurity from each split is assigned to the feature used for that split.\n",
    "\n",
    "3. **Sum Across the Tree**:\n",
    "   - The importance of each feature is the total reduction in impurity it provides across all splits.\n",
    "\n",
    "4. **Normalize**:\n",
    "   - The importance scores are scaled so they sum to 1, making it easier to compare features.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w-1ZcqEN-LH7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "141dc03f-c6e0-4cbb-8fca-a596cb08f94b"
   },
   "source": [
    "for feature, importance in zip(feature_data.columns, clf.feature_importances_):\n",
    "    print(f'{feature:<43} {importance:0.2f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HL_BERf-LH8"
   },
   "source": [
    "As we can see, the model assigns higher importance to **onshore nuclear generation**, though the importance is distributed across several features. This spread suggests the model considers multiple factors when predicting the target, rather than relying heavily on a single feature.\n",
    "\n",
    "---\n",
    "\n",
    "### Visualizing the Decision Tree\n",
    "\n",
    "A great way to understand a decision tree model is to **visualize the tree itself**. This lets us see:\n",
    "- How the data is split at each node.\n",
    "- Which features and thresholds the model uses for decisions.\n",
    "- The tree’s overall structure, including depth and complexity.\n",
    "\n",
    "We’ll use the [Graphviz](https://www.graphviz.org/) library to create a visual representation of our trained decision tree.\n",
    "\n",
    "#### Steps to Visualize:\n",
    "1. **Export the Tree**:\n",
    "   - Use `export_graphviz` to save the tree structure to a `.dot` file. This file describes the tree in a format that Graphviz can read.\n",
    "2. **Read the File**:\n",
    "   - Open and read the `.dot` file into Python.\n",
    "3. **Generate the Visualization**:\n",
    "   - Use `graphviz.Source` to render and display the tree."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nQ2xJfJm-LH8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "3bec6df6-ed28-458a-87d3-70d8a545bfd0"
   },
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz  # Library for creating visualizations\n",
    "\n",
    "# Export the decision tree to a .dot file\n",
    "export_graphviz(clf, out_file=\"mytree.dot\", feature_names=feature_data.columns)\n",
    "\n",
    "# Read the .dot file back in\n",
    "with open(\"mytree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "# Display the tree\n",
    "graphviz.Source(dot_graph)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EgolEWB-LH8"
   },
   "source": [
    "### Interpreting the Decision Tree Visualization\n",
    "\n",
    "The decision tree visualization provides a detailed view of how the model splits the data to make predictions. Here's how to interpret the key elements of the tree:\n",
    "\n",
    "#### Key Elements:\n",
    "1. **Nodes**:\n",
    "   - Each node represents a decision based on a specific feature and a threshold.\n",
    "   - Example: `generation solar <= 5.3` means the tree checks if the feature `generation solar` is less than or equal to 5.3.\n",
    "\n",
    "2. **Impurity**:\n",
    "   - Indicates the \"uncertainty\" or \"mix\" of the target classes in that node. For classification tasks, it’s often measured using Gini impurity.\n",
    "   - Lower impurity means the node contains mostly samples from one class.\n",
    "\n",
    "3. **Samples**:\n",
    "   - Shows the number of data points (rows) that reach that node.\n",
    "\n",
    "4. **Value**:\n",
    "   - Represents the number of samples in each class at the node. For example, `[30, 50]` means 30 samples are in class 0, and 50 are in class 1.\n",
    "\n",
    "5. **Leaves**:\n",
    "   - The terminal nodes where predictions are made. The class with the majority of samples in the leaf becomes the predicted class.\n",
    "\n",
    "#### Example Analysis:\n",
    "- Follow the splits from the root node to a leaf to see the sequence of decisions the model makes for a sample.\n",
    "- Look for features used frequently in splits higher up the tree—they are likely more important for the model’s predictions.\n",
    "- Check if the tree depth aligns with our `max_depth=10` setting. If the depth is less than 10, it means the model didn’t need the full depth to fit the data.\n",
    "\n",
    "---\n",
    "\n",
    "### YOUR TURN:\n",
    "1. Pick a random leaf node:\n",
    "   - What sequence of decisions leads to this leaf?\n",
    "   - How many samples are in this node?\n",
    "   - What is the predicted class for this node?\n",
    "\n",
    "2. Look at the root node:\n",
    "   - Which feature is used for the first split?\n",
    "   - Why might the model have chosen this feature for the root split?\n",
    "\n",
    "3. Examine the feature thresholds:\n",
    "   - Do any thresholds surprise you? Why or why not?\n",
    "\n",
    "By answering these questions, you’ll gain a deeper understanding of how the decision tree is making predictions and how it prioritizes features during splits.\n",
    "\n",
    "To reduce the degree to which this tree is overfit to the training data, we can force the tree to be of some *maximum depth*. This ensures the tree won't be able to just keep generating new layers to properly classify every sample in the training stage (and, thus, presumably generalize better to the test set).\n",
    "\n",
    "Let's try limiting the max depth to 2 and visualizing the resulting tree."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4uDkSy0a-LH9",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "outputId": "3b04b557-d7d7-4b1f-a3b3-9e7ca78c4c7f"
   },
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth = 2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "export_graphviz(clf, out_file=\"mytree.dot\", feature_names=feature_data.columns)\n",
    "with open(\"mytree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUJdXnp--LH9"
   },
   "source": [
    "Much simpler!"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameter Tuning with Grid Search\n",
    "\n",
    "A decision tree has several **hyperparameters** that control its structure and performance. Adjusting these hyperparameters can significantly affect the model's ability to generalize to unseen data. Here are some commonly tuned hyperparameters:\n",
    "\n",
    "1. **Max Tree Depth**:\n",
    "   - Defines how \"tall\" the tree can grow.\n",
    "   - A deeper tree can model more complex patterns but is also more prone to overfitting.\n",
    "\n",
    "2. **Minimum Samples Per Leaf**:\n",
    "   - Specifies the minimum number of training samples required in a leaf node.\n",
    "   - Higher values prevent the tree from creating overly specific splits.\n",
    "\n",
    "3. **Minimum Samples to Split**:\n",
    "   - Controls the minimum number of samples required to create a decision split at a node.\n",
    "   - Higher values encourage simpler trees.\n",
    "\n",
    "#### Cross-Validation\n",
    "**Cross-validation** is a technique used to evaluate a model's performance. It involves splitting the data into multiple subsets (folds). The model is trained on some folds and validated on the remaining ones, rotating through all folds. This helps ensure the model is evaluated across the entire dataset, providing a more reliable estimate of its performance.\n",
    "\n",
    "<img src=\"https://github.com/lyeskhalil/mlbootcamp/blob/master/img/cross-val.png?raw=1\" width=\"500\"/>\n",
    "\n",
    "For example, in **5-fold cross-validation**, the dataset is split into five parts. The model is trained on four parts and validated on the fifth, repeating this process five times with a different validation fold each time.\n",
    "\n",
    "#### Grid Search\n",
    "Grid Search systematically tests all possible combinations of hyperparameters from a predefined grid to find the best configuration. While computationally expensive, it ensures no combinations are overlooked. Scikit-learn’s `GridSearchCV` makes this process efficient and user-friendly."
   ],
   "metadata": {
    "id": "T2gqE8y3_yXP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import tree\n",
    "from time import time\n",
    "\n",
    "# Initialize the model\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "hyperparameter_search = {\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 8, 11],\n",
    "    'min_samples_leaf': [2, 5, 8, 11]\n",
    "}\n",
    "\n",
    "# Set up the evaluation metric (accuracy in this case)\n",
    "evaluation_metric = make_scorer(accuracy_score, greater_is_better=True)\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search_cv = GridSearchCV(estimator=clf,\n",
    "                              param_grid=hyperparameter_search,\n",
    "                              scoring=evaluation_metric,\n",
    "                              n_jobs=-1,  # Use all available CPU cores\n",
    "                              cv=5,  # Perform 5-fold cross-validation\n",
    "                              verbose=3)\n",
    "\n",
    "# Perform the grid search\n",
    "start_time = time()\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "print(f'Grid search completed in {time() - start_time:.2f} seconds')\n",
    "\n",
    "# Print the results\n",
    "print(\"Best Parameters: \", grid_search_cv.best_params_)\n",
    "print(f'Best Cross-Validation Accuracy: {grid_search_cv.best_score_ * 100:0.2f}%')\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "clf = grid_search_cv.best_estimator_\n",
    "accuracy = accuracy_score(y_test, clf.predict(imp.transform(X_test)))\n",
    "print(f'Accuracy on Test Set: {accuracy * 100:0.2f}%')"
   ],
   "metadata": {
    "id": "zmpcYAMI_xyX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2732628d-480b-4b54-fcd7-91504abfea38"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grid Search Limitations\n",
    "\n",
    "In the cell above, we tested four values for each hyperparameter and used Grid Search to find the best combination from the defined search space. While Grid Search is a thorough method, you may have noticed a key drawback:\n",
    "\n",
    "#### Exponential Growth of Combinations\n",
    "As you add more hyperparameters or increase the number of values tested for each hyperparameter, the number of combinations grows exponentially. For example:\n",
    "- Testing 4 values for 3 hyperparameters results in $4^3 = 64$ combinations.\n",
    "- Testing 5 values for 4 hyperparameters results in $5^4 = 625$ combinations.\n",
    "\n",
    "This growth makes Grid Search computationally expensive and time-consuming, especially for:\n",
    "- **Large Datasets**: Where training and validating a model is already slow.\n",
    "- **Complex Models**: Like neural networks, where training can take hours or days per configuration.\n",
    "\n",
    "#### Practical Implications\n",
    "- Grid Search is generally more suitable for simpler models (e.g., decision trees, logistic regression) or smaller datasets where training is relatively fast.\n",
    "- For more complex models like neural networks, alternative methods such as **Random Search** or **Bayesian Optimization** are often preferred. These methods explore the hyperparameter space more efficiently without testing every single combination.\n",
    "\n",
    "---\n",
    "\n",
    "In this section, we explored **decision trees** and how they can be used for classification tasks. Here’s a summary of what we covered:\n",
    "\n",
    "1. **Training Decision Trees**:\n",
    "   - We trained a decision tree to predict the presence of clouds based on energy generation data.\n",
    "   - By limiting the tree’s depth, we ensured it was small enough to interpret and avoided overfitting.\n",
    "\n",
    "2. **Interpreting Feature Importances**:\n",
    "   - Decision trees provide insight into which features are most influential in making predictions, enhancing the model’s interpretability.\n",
    "\n",
    "3. **Visualizing the Tree**:\n",
    "   - We used Graphviz to visualize the decision tree, helping us understand how the model splits data and arrives at predictions.\n",
    "\n",
    "4. **Hyperparameter Tuning**:\n",
    "   - We explored the effect of tuning hyperparameters like `max_depth`, `min_samples_split`, and `min_samples_leaf` using **Grid Search**.\n",
    "   - While effective, Grid Search can become computationally expensive as the number of parameters and their values grow.\n",
    "\n",
    "#### Key Takeaways:\n",
    "- **Strengths of Decision Trees**:\n",
    "  - Easy to interpret and explain.\n",
    "  - Require minimal data preprocessing (e.g., no feature scaling).\n",
    "  - Can model non-linear relationships effectively.\n",
    "\n",
    "- **Limitations**:\n",
    "  - Prone to overfitting without proper constraints like limiting depth or minimum samples.\n",
    "  - Sensitive to changes in the training data, which can result in different splits.\n",
    "\n"
   ],
   "metadata": {
    "id": "Qrr1hd59EiVK"
   }
  },
  {
   "metadata": {
    "id": "--drxZvxMwVq"
   },
   "cell_type": "markdown",
   "source": [
    "# Neural Networks with Keras\n",
    "\n",
    "We’re now transitioning to using **neural networks** for making predictions with the **Keras** library. Keras is a high-level deep learning API, part of TensorFlow, that simplifies building, training, and evaluating neural networks. It’s widely used for both beginner and advanced machine learning tasks because of its clean and intuitive syntax.\n",
    "\n",
    "In this section, we’ll use Keras to build a **feedforward neural network** to perform a **regression task**. Unlike classification, where the goal is to predict discrete labels, regression focuses on predicting continuous values. Here, we’ll predict the **total energy consumed** based on weather conditions, aligning with real-world energy forecasting tasks.\n",
    "\n",
    "Keras provides:\n",
    "- **Ease of Use**: Build and train models with just a few lines of code.\n",
    "- **Flexibility**: Customize architectures for a wide range of problems.\n",
    "- **Integration**: Compatible with TensorFlow for deployment and scaling.\n",
    "\n",
    "With Keras, we can quickly experiment with different neural network architectures, adjust hyperparameters, and evaluate model performance using built-in utilities.\n",
    "\n",
    "---\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "To prepare the data for this regression task:\n",
    "1. **Define the Target (`y`)**:\n",
    "   - The target variable is `total load actual`, representing the actual energy consumed.\n",
    "\n",
    "2. **Define the Features (`X`)**:\n",
    "   - Features include weather-related variables like temperature, wind speed, cloud cover, and precipitation."
   ]
  },
  {
   "metadata": {
    "id": "e4erskPOMwVr"
   },
   "cell_type": "code",
   "source": [
    "target_data = df['total load actual']\n",
    "\n",
    "city_name_columns = [col for col in df.columns if 'city_name' in col]\n",
    "weather_main_columns = [col for col in df.columns if 'weather_main' in col]\n",
    "\n",
    "feature_data = df[['temp', 'temp_min', 'temp_max', 'pressure',\n",
    "                   'humidity', 'wind_speed', 'wind_deg', 'rain_1h', 'rain_3h', 'snow_3h',\n",
    "                   'clouds_all'] + city_name_columns + weather_main_columns]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "aoAjJCdGMwVr"
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_data, target_data, test_size=0.3, random_state=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "euN0UIHsMwVr"
   },
   "cell_type": "code",
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "imp.fit(X_train)\n",
    "X_train = imp.transform(X_train) # replace missing data using our imputer\n",
    "X_test = imp.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "ZeBH5Rm4MwVr"
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "-bt6Ojz8MwVr"
   },
   "cell_type": "markdown",
   "source": [
    "Let's check our data to confirm it's what we expect."
   ]
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "fDfnzOHCMwVs",
    "outputId": "c589eb0d-3698-4e2c-89c6-1273903155ac"
   },
   "cell_type": "code",
   "source": [
    "pd.DataFrame(X_train, columns=feature_data.columns)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "acEjCJwaMwVs",
    "outputId": "9fb7b204-600c-41ea-ff5d-13247c53f11e"
   },
   "cell_type": "code",
   "source": [
    "y_train"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "2chjs40LMwVs"
   },
   "cell_type": "markdown",
   "source": [
    "# Building a Neural Network with Keras\n",
    "\n",
    "With our `X` (features) and `y` (target) data prepared, we are now ready to build a **neural network** for our regression task. We’ll use the **Keras** library, which provides a high-level API for constructing and training neural networks. Specifically, we’ll use Keras’s **Sequential** model to create a simple feedforward neural network.\n",
    "\n",
    "The **Sequential** model is ideal for building neural networks where layers are stacked sequentially—each layer feeds its output to the next layer. This is perfect for straightforward architectures like feedforward networks.\n",
    "\n",
    "In this task:\n",
    "- **Input Layer**: Takes in the feature data (`X`).\n",
    "- **Hidden Layer**: Processes the data to learn patterns.\n",
    "- **Output Layer**: Predicts the target value (total energy consumed).\n",
    "\n",
    "---\n",
    "\n",
    "## Data Shape\n",
    "Before building the model, we need to record some essential information about the shape of our data:\n",
    "- **Input Shape**: The number of features in `X_train`, which determines the size of the input layer.\n",
    "- **Output Shape**: The number of target variables we’re predicting. For this regression task, it’s a single value.\n"
   ]
  },
  {
   "metadata": {
    "id": "h8uTl6YLMwVs"
   },
   "cell_type": "code",
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input\n",
    "\n",
    "input_shape = X_train.shape[1]\n",
    "output_shape = 1 # We are predicting a single value"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "mpWcs3LtMwVs"
   },
   "cell_type": "markdown",
   "source": [
    "### Building a Neural Network Model\n",
    "\n",
    "Now that we’ve explored the data, let’s build a simple neural network model to classify the iris dataset. We’ll use Keras, a high-level API for building and training neural networks in Python.\n",
    "\n",
    "#### Key Components:\n",
    "- **`Sequential`**: A linear stack of layers where each layer feeds into the next.\n",
    "- **`Dense`**: Fully connected layers where each neuron connects to every neuron in the previous and next layers.\n",
    "- **`Input`**: Defines the shape of the input data for the first layer.\n",
    "- **Activation Function**: We’ll use the **ReLU** (Rectified Linear Unit) activation function for the hidden layer, which introduces non-linearity into the model.\n",
    "\n",
    "#### Model Architecture:\n",
    "1. **Input Layer**:\n",
    "   - The input layer size (`input_shape`) should match the number of features in the input data.\n",
    "2. **Hidden Layer**:\n",
    "   - We’ll include one hidden layer with 10 neurons, each applying the ReLU activation function.\n",
    "3. **Output Layer**:\n",
    "   - The output layer size (`output_shape`) depends on the number of classes in the dataset (e.g., 3 for iris classification).\n",
    "\n",
    "#### Compiling the Model:\n",
    "- **Optimizer**: Stochastic Gradient Descent (`'sgd'`) will be used to update weights during training.\n",
    "- **Loss Function**: Mean Absolute Error (`'mean_absolute_error'`) will evaluate how far predictions are from the true values."
   ]
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "yUL41VlFMwVs",
    "outputId": "058a910d-fda2-43c8-f466-93294b0277e8"
   },
   "cell_type": "code",
   "source": [
    "# Build the model\n",
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape=(input_shape,)),  # Input layer\n",
    "        Dense(10),                    # Hidden layer with 10 neurons\n",
    "        Activation('relu'),           # ReLU activation\n",
    "        Dense(output_shape)           # Output layer with one neuron per class\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='mean_absolute_error')\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "3zd4aFBnMwVt"
   },
   "cell_type": "markdown",
   "source": [
    "### Understanding the Model Summary\n",
    "\n",
    "The model summary provides an overview of the architecture of your neural network. Here's what each part means in simple terms:\n",
    "\n",
    "#### Key Terms:\n",
    "- **Layer (type)**: This column lists the layers in your model and their types. For example:\n",
    "  - `Dense`: A fully connected layer where every neuron connects to every neuron in the previous and next layers.\n",
    "  - `Activation`: Applies a mathematical function (like ReLU) to the outputs of the previous layer.\n",
    "- **Output Shape**: This column describes the size of the output from each layer:\n",
    "  - `(None, 10)`: The `None` represents the batch size (which is dynamic and can vary during training), while `10` is the number of neurons in that layer.\n",
    "- **Param #**: This column shows the number of trainable parameters (weights and biases) in each layer.\n",
    "\n",
    "#### Layer Breakdown:\n",
    "1. **First Dense Layer (`dense`)**:\n",
    "   - **Output Shape**: `(None, 10)` → The layer has 10 neurons.\n",
    "   - **Param #**: `290` → The parameters are calculated as:\n",
    "     - $ \\text{(Number of inputs)} \\times \\text{(Number of neurons)} + \\text{(Number of biases)} $\n",
    "     - $ 28 \\times 10 + 10 = 290 $, where 28 is the number of features from the input.\n",
    "2. **Activation Layer (`activation`)**:\n",
    "   - **Output Shape**: `(None, 10)` → The same size as the previous layer because this layer just applies the ReLU function.\n",
    "   - **Param #**: `0` → No parameters are learned here; it's just applying a function.\n",
    "3. **Second Dense Layer (`dense_1`)**:\n",
    "   - **Output Shape**: `(None, 1)` → A single output neuron, typically used for predictions.\n",
    "   - **Param #**: `11` → The parameters are calculated as:\n",
    "     - $ 10 \\times 1 + 1 = 11 $, where 10 is the number of neurons from the previous layer.\n",
    "\n",
    "#### Totals:\n",
    "- **Total Params**: `301` → The sum of all trainable parameters in the network.\n",
    "- **Trainable Params**: `301` → All the parameters in this model can be updated during training.\n",
    "- **Non-Trainable Params**: `0` → There are no fixed parameters in this model.\n",
    "\n",
    "### Training the Model\n",
    "\n",
    "The `model.fit()` function is where the magic happens—this is where the model learns from the training data by adjusting its weights to minimize the error (loss). Let’s break down the parameters in this code:\n",
    "\n",
    "#### Parameters Explained:\n",
    "- **`X_train, y_train`**: These are the input features (`X_train`) and corresponding target labels (`y_train`) used for training the model. The model uses this data to learn patterns and make predictions.\n",
    "- **`epochs=5`**: An **epoch** is one complete pass through the entire training dataset. Setting this to `5` means the model will go through the dataset five times.\n",
    "- **`batch_size=128`**: The data is divided into **batches** of 128 samples. The model updates its weights after processing each batch, which can speed up training compared to using the entire dataset at once.\n",
    "- **`validation_data=(X_test, y_test)`**: This is the data used to evaluate the model’s performance after each epoch. It is not used for training, which helps prevent overfitting and ensures the model generalizes well to unseen data.\n",
    "\n",
    "#### What Happens During Training:\n",
    "1. **Forward Pass**:\n",
    "   - The model processes a batch of data, makes predictions, and computes the loss (difference between predictions and actual labels).\n",
    "2. **Backward Pass**:\n",
    "   - The model calculates gradients of the loss with respect to its parameters and updates the parameters using the optimizer (in this case, stochastic gradient descent).\n",
    "3. **Validation**:\n",
    "   - After each epoch, the model evaluates its performance on the validation data to track how well it generalizes.\n"
   ]
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aNCLpP72MwVt",
    "outputId": "87386f24-5f53-4992-cb08-8beb4f9e4c76"
   },
   "cell_type": "code",
   "source": [
    "model.fit(\n",
    "    X_train, y_train,                 # Training data\n",
    "    epochs=5,                         # Train for 5 complete passes through the data\n",
    "    batch_size=128,                   # Update weights after every 128 samples\n",
    "    validation_data=(X_test, y_test)  # Use separate data for validation\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluating the Model: Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE)\n",
    "\n",
    "To assess how well our model is performing on the testing data, we calculate two common evaluation metrics:\n",
    "\n",
    "1. **Mean Absolute Error (MAE)**:\n",
    "   - This metric gives the average absolute difference between the predicted values (`y_pred`) and the true values (`y_test`).\n",
    "   - It is measured in the same units as the target variable, making it easy to interpret.\n",
    "\n",
    "   Formula:\n",
    "   $$\n",
    "   \\text{MAE} = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i|\n",
    "   $$\n",
    "   Where:\n",
    "   - $ y_i $: True value\n",
    "   - $ \\hat{y}_i $: Predicted value\n",
    "   - $ n $: Number of samples\n",
    "\n",
    "2. **Mean Absolute Percentage Error (MAPE)**:\n",
    "   - This metric provides the average percentage difference between predictions and true values. It’s particularly useful when you want to understand error relative to the size of the true values.\n",
    "   - The result is expressed as a percentage.\n",
    "\n",
    "   Formula:\n",
    "   $$\n",
    "   \\text{MAPE} = \\frac{1}{n} \\sum_{i=1}^n \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right| \\times 100\n",
    "   $$\n",
    "\n"
   ],
   "metadata": {
    "id": "1R0BqQP3Q6BG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'MAE:  {mean_absolute_error(y_test, y_pred):.02f}')\n",
    "print(f'MAPE: {mean_absolute_percentage_error(y_test, y_pred)*100:.02f}%')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-QAHIrgQdTX",
    "outputId": "2b5ad974-5822-40a8-9a06-f9d623bdd395"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualizing a Single Prediction Through the Network\n",
    "\n",
    "Understanding how a single input flows through a neural network can help demystify how predictions are made. Let’s break down how our model processes one test sample to produce a prediction.\n",
    "\n",
    "#### Steps in the Network:\n",
    "1. **Input Layer**: The input data (features) is fed into the network.\n",
    "2. **Hidden Layer**: The input is multiplied by weights, biases are added, and the result is passed through an activation function (ReLU in this case).\n",
    "3. **Output Layer**: The transformed data is further processed to produce the final prediction.\n",
    "\n",
    "Here’s an example using one test sample:"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Select a single test sample\n",
    "sample_index = 0\n",
    "single_input = X_test[sample_index]  # Shape: (number of features,)\n",
    "true_value = y_test[sample_index]\n",
    "\n",
    "# Forward pass through the network\n",
    "print(f\"Input features:\\n{single_input}\")\n",
    "\n",
    "# Layer 1: Compute the weighted sum + bias, then apply ReLU\n",
    "hidden_layer_weights = model.layers[0].get_weights()[0]\n",
    "hidden_layer_biases = model.layers[0].get_weights()[1]\n",
    "\n",
    "# Build the equation for the hidden layer\n",
    "equations = []\n",
    "for neuron_index in range(hidden_layer_weights.shape[1]):\n",
    "    terms = [\n",
    "        f\"{hidden_layer_weights[feature_index, neuron_index]:.2f}*x{feature_index + 1}\"\n",
    "        for feature_index in range(hidden_layer_weights.shape[0])\n",
    "    ]\n",
    "    bias = hidden_layer_biases[neuron_index]\n",
    "    equation = \" + \".join(terms) + f\" + {bias:.2f}\"\n",
    "    equations.append(f\"\\nNeuron {neuron_index + 1}:\\n{equation}\")\n",
    "\n",
    "# Print the equations for each neuron in the hidden layer\n",
    "for eq in equations:\n",
    "    print(eq)\n",
    "\n",
    "hidden_layer_output = np.dot(single_input, hidden_layer_weights) + hidden_layer_biases\n",
    "print(f\"\\nEquation results (pre-activation):\\n{hidden_layer_output}\")\n",
    "hidden_layer_output = np.maximum(0, hidden_layer_output)  # ReLU activation\n",
    "print(f\"\\nEquation results (post-activation):\\n{hidden_layer_output}\")\n",
    "\n",
    "# Output layer: Compute the final weighted sum + bias\n",
    "output_layer_weights = model.layers[2].get_weights()[0]\n",
    "output_layer_biases = model.layers[2].get_weights()[1]\n",
    "\n",
    "output_terms = [\n",
    "    f\"{output_layer_weights[hidden_index, 0]:.2f}*h{hidden_index + 1}\"\n",
    "    for hidden_index in range(output_layer_weights.shape[0])\n",
    "]\n",
    "output_bias = output_layer_biases[0]\n",
    "output_equation = \" + \".join(output_terms) + f\" + {output_bias:.2f}\"\n",
    "\n",
    "# Print the output layer equation\n",
    "print(f\"\\nOutput: {output_equation}\")\n",
    "\n",
    "output = np.dot(hidden_layer_output, output_layer_weights) + output_layer_biases\n",
    "print(f\"\\nOutput (prediction): {output[0]:.0f}\")\n",
    "\n",
    "# Compare the prediction with the true value\n",
    "print(f\"True value:          {true_value:.0f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "In this lab, we explored and implemented two powerful machine learning techniques: **Decision Trees** and **Neural Networks**. Through hands-on coding and analysis, we gained insights into their strengths, limitations, and practical applications. Here’s a summary of what we accomplished:\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "#### Decision Trees\n",
    "1. **How They Work**:\n",
    "   - Decision trees split data based on feature thresholds, creating a tree-like structure to make predictions.\n",
    "   - They are intuitive and interpretable, making them suitable for explaining decisions.\n",
    "\n",
    "2. **Implementation**:\n",
    "   - We trained a decision tree to predict cloud presence using weather and energy generation data.\n",
    "   - We visualized the tree structure, which helped us understand the model’s decision-making process.\n",
    "\n",
    "3. **Limitations**:\n",
    "   - Decision trees can overfit without constraints like limiting depth or requiring minimum samples per split.\n",
    "   - They are sensitive to small changes in the data.\n",
    "\n",
    "#### Neural Networks\n",
    "1. **How They Work**:\n",
    "   - Neural networks process data through layers of neurons, each applying mathematical transformations and activation functions to learn patterns.\n",
    "   - They excel at capturing complex, non-linear relationships in data.\n",
    "\n",
    "2. **Implementation**:\n",
    "   - We built and trained a feedforward neural network using Keras to predict energy consumption based on weather features.\n",
    "   - By visualizing the flow of a single prediction through the network, we demystified how inputs are transformed layer by layer into outputs.\n",
    "\n",
    "3. **Evaluation**:\n",
    "   - Using metrics like Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE), we evaluated the network’s performance, understanding the accuracy and scale of predictions.\n",
    "\n",
    "### Comparing Decision Trees and Neural Networks\n",
    "- **Strengths**:\n",
    "  - Decision Trees: Simple, interpretable, require little data preprocessing.\n",
    "  - Neural Networks: Flexible, powerful for complex tasks, adaptable to various problem types.\n",
    "\n",
    "- **Limitations**:\n",
    "  - Decision Trees: Susceptible to overfitting, less effective for highly non-linear problems.\n",
    "  - Neural Networks: Require more data and computational resources, harder to interpret.\n",
    "\n",
    "### Bonus Task: Extending the Neural Network\n",
    "\n",
    "To deepen your understanding of neural networks, try **extending the architecture** of the model you built. You can either:\n",
    "1. Add additional hidden layers to increase the model's depth.\n",
    "2. Increase the number of neurons in the existing hidden layer(s) to make the model wider.\n",
    "\n",
    "#### Directions:\n",
    "1. **Adding a New Hidden Layer**:\n",
    "   - Insert a new `Dense` layer between the existing layers.\n",
    "   - Use the `Activation` layer to apply the ReLU activation function to this new layer.\n",
    "   - Ensure the number of neurons in the new layer fits your design (e.g., 20 or 30 neurons).\n",
    "   - Remember that deeper networks can learn more complex patterns but might require more epochs to train effectively.\n",
    "\n",
    "2. **Increasing the Width of an Existing Layer**:\n",
    "   - Modify the number of neurons in the hidden layer(s) by increasing the first argument in the `Dense` function (e.g., from 10 to 50 neurons).\n",
    "   - Wider layers can capture more details from the input but may also increase the risk of overfitting.\n",
    "\n",
    "3. **Re-compiling the Model**:\n",
    "   - After making changes to the architecture, recompile the model using the same optimizer and loss function.\n",
    "\n",
    "4. **Retraining the Model**:\n",
    "   - Fit the updated model on the training data using the same number of epochs and batch size.\n",
    "   - Compare the training and validation metrics with the original model to assess the impact of the changes.\n",
    "\n",
    "5. **Optional Exploration**:\n",
    "   - Try using a different activation function, such as `tanh` or `sigmoid`, in the new layers.\n",
    "\n",
    "#### Questions to Answer:\n",
    "- Did the additional layers or neurons improve the model’s performance? Why or why not?\n",
    "- How did the changes affect training time and validation metrics?\n",
    "- What trade-offs did you observe between model complexity and generalization?\n",
    "\n",
    "Feel free to document your findings and share them with the group for discussion!\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
