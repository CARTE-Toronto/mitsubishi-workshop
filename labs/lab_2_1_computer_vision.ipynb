{
 "cells": [
  {
   "metadata": {
    "id": "858d6cd9fd7f48a7"
   },
   "cell_type": "markdown",
   "source": [
    "# AI Workshop - Lab 2-1: Computer Vision\n",
    "\n",
    "In this lab, we will use pre-trained models to classify machine part defects. Like yesterday, we will be working with Keras and TensorFlow, but this time we will use the `tf.keras.applications` module to load pre-trained models.\n",
    "\n",
    "### Data Overview\n",
    "\n",
    "The dataset provided for this lab contains images of an automotive part, the **Fender Apron**, captured under varying conditions such as different angles and scales. The dataset has already been labeled as either **defective** or **healthy**, making it ideal for supervised learning tasks.\n",
    "\n",
    "- **Total Images**: 250\n",
    "  - **Healthy Parts**: 139 images\n",
    "  - **Defective Parts**: 111 images\n",
    "- **Train/Test Split**:\n",
    "  - **Training Set**: 90% of the data\n",
    "  - **Test Set**: 10% of the data (25 randomly selected images)\n",
    "\n",
    "### Key Steps in Lab\n",
    "1. **Exploration**: We'll start by visualizing the dataset, inspecting some sample images to understand variations and potential challenges.\n",
    "2. **Preprocessing**: Learn to preprocess images by resizing, normalizing pixel values, and augmenting the dataset to simulate real-world scenarios.\n",
    "3. **Model Selection**:\n",
    "   - We'll use the MobileNetV2 architecture, a lightweight and efficient model available in `tf.keras.applications`.\n",
    "   - The pre-trained model will be fine-tuned to classify images into **defective** and **healthy** categories.\n",
    "4. **Evaluation**:\n",
    "   - Evaluate model performance using metrics such as **f1-score**, **precision**, and **recall**.\n",
    "   - Analyze confusion matrices and visualize predictions for better interpretability.\n",
    "\n",
    "### Goals\n",
    "By the end of this lab, you will:\n",
    "- Understand the concept of transfer learning and how to adapt a pre-trained model to solve specific problems.\n",
    "- Gain hands-on experience with training and deploying a defect detection system.\n",
    "- Learn to create APIs for model deployment using Flask.\n",
    "\n",
    "### Getting Started\n",
    "- Open the `Machine defect detection.ipynb` notebook for a guided walkthrough.\n",
    "- Pre-process the dataset using the `functions.py` script.\n",
    "- Explore the live demo at [Demo Link](https://kapilve.pythonanywhere.com/) to see the final application in action.\n",
    "\n",
    "Now, let's dive into the **dataset preparation** and explore how these images can be preprocessed for model training!\n",
    "\n",
    "### Loading the Dataset\n",
    "\n",
    "We will start by loading the dataset and visualizing a few sample images to understand the data distribution and characteristics. The dataset is already organized for you into training and testing sets, with separate folders for **defective** and **healthy** parts. Keras makes it easy for us to load images like this using the `image_dataset_from_directory` function."
   ],
   "id": "858d6cd9fd7f48a7"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bc3ccb0a28f46cb",
    "outputId": "6570a36f-62c9-4f96-8ad4-6f34b03fa9c0"
   },
   "cell_type": "code",
   "source": [
    "!wget https://github.com/alexwolson/mdlw_materials/raw/refs/heads/main/data/parts_dataset.tar.gz"
   ],
   "id": "2bc3ccb0a28f46cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "cf4c0b1f9e705c82"
   },
   "cell_type": "code",
   "source": [
    "!tar -xf parts_dataset.tar.gz"
   ],
   "id": "cf4c0b1f9e705c82",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "initial_id",
    "outputId": "477dd492-2844-4ee7-d4ee-2dc7db49b8b7"
   },
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the dataset directory\n",
    "dataset_dir = Path('parts_dataset')\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    dataset_dir / 'train',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    dataset_dir / 'test',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "id": "d3e1f93ea2a473e",
    "outputId": "34f20e40-9db8-4f0e-8039-291b4282b8cf"
   },
   "cell_type": "code",
   "source": [
    "# Visualize the first 9 images from the training set\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(\"defective\" if labels[i] == 0 else \"healthy\")\n",
    "        plt.axis(\"off\")"
   ],
   "id": "d3e1f93ea2a473e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "302033d4f0b96458"
   },
   "cell_type": "markdown",
   "source": [
    "It might be easier to tell in some images than others that there is a defect - see if you can spot the differences!\n",
    "\n",
    "### Preprocessing the Images\n",
    "\n",
    "As you might have noticed, we have already done some of the preprocessing for this dataset for you. Namely, we've done the following:\n",
    "\n",
    "- Resizing: The original images are 4160 × 3120 pixels, which is too large for most models to handle. We've resized them to 224 × 224 pixels (although the files are 480 × 480 pixels, so there is some room for further resizing). We also normalized to an aspect ratio of 1:1 by adding black bars to the sides of the images where necessary.\n",
    "- Train-Test Split: We've split the dataset into training and testing sets, with 90% of the data used for training and 10% for testing.\n",
    "\n",
    "Now it's time to complete the preprocessing. We'll do the following:\n",
    "\n",
    "- Normalization: Rescale pixel values to the range [0, 1]. By default, the pixel values are in the range [0, 255] (8-bit integers).\n",
    "- Data Augmentation: Apply random transformations to the training images to simulate real-world scenarios. This allows us to artificially increase the size of the training set and improve model generalization.\n",
    "- Configure the Dataset: Optimize the dataset for performance by prefetching, caching, and shuffling the images.\n",
    "\n",
    "Let's start by rescaling the pixel values to the range [0, 1]. Above we used `matplotlib` to visualize the images, but for the model they are simply a matrix of numbers. Run the below cell to see the pixel values of the first image in the training set."
   ],
   "id": "302033d4f0b96458"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b888b44480d52d78",
    "outputId": "a422f4a2-2aaa-452a-9b3f-d1a7c55ec222"
   },
   "cell_type": "code",
   "source": [
    "for images, labels in train_dataset.take(1):\n",
    "    print(images[0].shape)\n",
    "    print(images[0][100]) # Slice in the middle of the image\n",
    "    break"
   ],
   "id": "b888b44480d52d78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "bc4b3f8dc043da45"
   },
   "cell_type": "markdown",
   "source": [
    "As you can see, the values are all between 0 and 255. You'll also notice that they come in sets of 3. This is because the images are in RGB format, so each pixel has 3 values (red, green, and blue)."
   ],
   "id": "bc4b3f8dc043da45"
  },
  {
   "metadata": {
    "id": "3f37186fe65647e"
   },
   "cell_type": "code",
   "source": [
    "# Normalize pixel values\n",
    "from keras.layers import Rescaling\n",
    "normalization_layer = Rescaling(1./255)\n",
    "# Apply normalization to the dataset\n",
    "normalized_train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))"
   ],
   "id": "3f37186fe65647e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba0547e086b81bd7",
    "outputId": "6b49ba22-9d4d-46cd-f6ec-cc7cec0caecd"
   },
   "cell_type": "code",
   "source": [
    "for images, labels in normalized_train_dataset.take(1):\n",
    "    print(images[0].shape)\n",
    "    print(images[0][100]) # Slice in the middle of the image\n",
    "    break"
   ],
   "id": "ba0547e086b81bd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "91421debc0a1a1dc"
   },
   "cell_type": "markdown",
   "source": [
    "Now that the pixel values are normalized, we can move on to data augmentation. This step is crucial for improving the model's generalization and robustness. By applying random transformations to the training images, we can simulate real-world scenarios and prevent overfitting.\n",
    "\n",
    "We will take advantage of the convenient image augmentation layers provided by Keras. These layers can be added directly to the model architecture, making it easy to experiment with different augmentation strategies. We will use the layers in that way, but first let's get a sense of what they do to our images by visualizing a few examples.\n",
    "\n",
    "Run the below cell to see some augmented images."
   ],
   "id": "91421debc0a1a1dc"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "id": "c65665a8752bf57f",
    "outputId": "0b6413f0-364b-403a-bafb-efcd3604d770"
   },
   "cell_type": "code",
   "source": [
    "from keras.layers import RandomCrop, RandomFlip, RandomRotation, RandomZoom, RandomContrast, RandomBrightness\n",
    "\n",
    "# Define the augmentation layers\n",
    "augmentation_layers = tf.keras.Sequential([\n",
    "    RandomCrop(224, 224),\n",
    "    RandomFlip(\"horizontal_and_vertical\"),\n",
    "    RandomRotation(0.2),\n",
    "    RandomZoom(0.2, 0.2),\n",
    "    RandomContrast(0.2),\n",
    "    RandomBrightness(0.2),\n",
    "])\n",
    "\n",
    "# Apply augmentation to the dataset\n",
    "augmented_train_dataset = train_dataset.map(lambda x, y: (augmentation_layers(x), y))\n",
    "\n",
    "# Visualize the first 9 augmented images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in augmented_train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(\"defective\" if labels[i] == 0 else \"healthy\")\n",
    "        plt.axis(\"off\")"
   ],
   "id": "c65665a8752bf57f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "58f531285f46620f"
   },
   "cell_type": "markdown",
   "source": [
    "By applying these transformations, we can see that the images are now slightly different from the original ones. This variety will help the model learn to generalize better and make more accurate predictions.\n",
    "\n",
    "### Configure the Dataset\n",
    "\n",
    "Finally, we will configure the dataset for performance by optimizing it for training. We will apply the following optimizations:\n",
    "\n",
    "- **Prefetching**: Overlapping the preprocessing and model execution to improve training speed.\n",
    "- **Caching**: Caching the data to memory to avoid loading the images from disk every time.\n",
    "- **Shuffling**: Randomizing the order of the images to prevent the model from learning the sequence of images.\n",
    "\n",
    "Let's apply these optimizations to the training and testing datasets."
   ],
   "id": "58f531285f46620f"
  },
  {
   "metadata": {
    "id": "e98e6f57a691da70"
   },
   "cell_type": "code",
   "source": [
    "# Configure the training dataset\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1000)\n",
    "\n",
    "# Configure the testing dataset\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.cache()\n",
    "test_dataset = test_dataset.shuffle(buffer_size=1000)"
   ],
   "id": "e98e6f57a691da70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "6d9ec971828a86c0"
   },
   "cell_type": "markdown",
   "source": [
    "# Model Selection\n",
    "\n",
    "In contemporary deep learning tasks, it's common to take advantage of _pre-trained_ models. These models have been trained on large-scale datasets and have learned to extract useful features from images. By leveraging pre-trained models, we can significantly reduce the training time and computational resources required to build a new model.\n",
    "\n",
    "In this lab, we will use the **MobileNetV2** architecture, a lightweight and efficient model available in `tf.keras.applications`. MobileNetV2 is designed for mobile and embedded vision applications, making it a suitable choice for our defect detection task.\n",
    "\n",
    "Let's go ahead and load the MobileNetV2 model with pre-trained weights and fine-tune it on our dataset."
   ],
   "id": "6d9ec971828a86c0"
  },
  {
   "metadata": {
    "id": "be1d4234eaac6d64"
   },
   "cell_type": "markdown",
   "source": [
    "To adapt the pre-trained MobileNetV2 model to our defect detection task, we need to fine-tune it on our dataset. Fine-tuning involves updating the model's weights to learn the specific features of our dataset. We will freeze the base layers of the model and train only the top layers, which are randomly initialized.\n",
    "\n",
    "Let's add the top layers to the model and compile it for training."
   ],
   "id": "be1d4234eaac6d64"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 911
    },
    "id": "39c49004f87b7911",
    "outputId": "1c423b43-2d96-4439-acc3-57223e16bb2f"
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, RandomFlip, RandomRotation, RandomZoom, RandomTranslation, Rescaling, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load and preprocess the datasets\n",
    "batch_size = 32\n",
    "image_size = (224, 224)\n",
    "\n",
    "# Define data augmentation and rescaling layers\n",
    "data_augmentation = Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomRotation(0.1),\n",
    "    RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "# Rescale pixel values to [0, 1]\n",
    "rescaling = Rescaling(1.0 / 255)\n",
    "\n",
    "# Load the MobileNetV2 model with pre-trained weights\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=image_size + (3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze the base layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Input(shape=image_size + (3,)),\n",
    "    data_augmentation,    # Apply data augmentation\n",
    "    rescaling,            # Rescale pixel values\n",
    "    base_model,           # Pre-trained base model\n",
    "    GlobalAveragePooling2D(),  # Global average pooling\n",
    "    Dense(128, activation='relu'),  # Fully connected layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Prefetch the datasets for optimized performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=15,\n",
    "    validation_data=val_dataset\n",
    ")\n"
   ],
   "id": "39c49004f87b7911",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "bb10065ab18b9b95"
   },
   "cell_type": "markdown",
   "source": [
    "The model has been successfully trained on the dataset, and we can observe the training and validation accuracy improving over the epochs. The final accuracy will depend on the dataset size, model architecture, and training duration. In practice, it's common to experiment with different models, hyperparameters, and training strategies to achieve the best performance.\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "To evaluate the model's performance, we need to compute various metrics such as accuracy, precision, recall, and F1-score. These metrics provide insights into the model's ability to classify defective and healthy parts correctly. We'll also look at `saliency maps` to visualize the regions of the image that the model focuses on during prediction.\n",
    "\n",
    "Let's start by computing the evaluation metrics for the model."
   ],
   "id": "bb10065ab18b9b95"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c144f17717a36cbc",
    "outputId": "d717c8de-f1a4-4f76-9fa1-a6c0bae4f6ae"
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Get the predictions and true labels\n",
    "y_pred = model.predict(test_dataset).flatten()\n",
    "y_true = np.concatenate([y for x, y in test_dataset])\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "report = classification_report(y_true, y_pred)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(report)\n",
    "print(conf_matrix)"
   ],
   "id": "c144f17717a36cbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "9811ae916bcab8a6"
   },
   "cell_type": "markdown",
   "source": [
    "We can see that the model performs decently well in identifying healthy parts, but recall on defective parts is lower. This suggests that the model may be biased towards predicting healthy parts, which could be due to class imbalance or insufficient training data.\n",
    "\n",
    "### Visualizing Predictions\n",
    "\n",
    "To gain a better understanding of the model's predictions, we can visualize the images along with their predicted labels. This will help us identify any patterns or inconsistencies in the model's predictions.\n",
    "\n",
    "Let's visualize a few sample images along with their predicted labels."
   ],
   "id": "9811ae916bcab8a6"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 868
    },
    "id": "dd233e712d436758",
    "outputId": "5ec478e6-919c-4f9a-fad6-bf1c834f89a7"
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the first batch of images and labels\n",
    "for images, labels in test_dataset.take(1):\n",
    "    y_pred = model.predict(images).flatten()\n",
    "    y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(f'Predicted: {\"defective\" if y_pred[i] == 0 else \"healthy\"}\\nTrue: {\"defective\" if labels[i] == 0 else \"healthy\"}')\n",
    "        plt.axis(\"off\")"
   ],
   "id": "dd233e712d436758",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "f5be53b900e800ff"
   },
   "cell_type": "markdown",
   "source": [
    "## Improving Performance\n",
    "\n",
    "It's your turn! Let's see if you can improve the model's performance by experimenting with different strategies. Here are some ideas to get you started:\n",
    "\n",
    "- **Data Augmentation**: Try different combinations of data augmentation techniques to increase the diversity of the training set. Consider that too much augmentation can lead to overfitting - maybe we started too high?\n",
    "- **Hyperparameter Tuning**: Experiment with different learning rates, batch sizes, and optimizers to find the optimal configuration for training.\n",
    "- **Model Architecture**: Try using a different pre-trained model or building a custom architecture to see if it improves performance.\n",
    "- **Fine-Tuning**: We _froze_ the base model to only train the top layers. We can unfreeze some of the base layers and train them along with the top layers to learn more specific features from the dataset."
   ],
   "id": "f5be53b900e800ff"
  },
  {
   "metadata": {
    "id": "c5d469ab0e96afaf"
   },
   "cell_type": "markdown",
   "source": [
    "# Data Augmentation\n",
    "\n",
    "You can make changes to the data augmentation layers in the cell below to experiment with different combinations of transformations. Try adding or removing layers, changing the parameters, or using different types of augmentations to see how they affect the model's performance."
   ],
   "id": "c5d469ab0e96afaf"
  },
  {
   "metadata": {
    "id": "25bc7ace927ae20b"
   },
   "cell_type": "code",
   "source": [
    "from keras.layers import RandomCrop, RandomFlip, RandomRotation, RandomZoom, RandomContrast, RandomBrightness\n",
    "\n",
    "# Define the augmentation layers\n",
    "data_augmentation = Sequential([\n",
    "    RandomCrop(224, 224),\n",
    "    RandomFlip(\"horizontal_and_vertical\"),\n",
    "    RandomRotation(0.2),\n",
    "    RandomZoom(0.2, 0.2),\n",
    "    RandomContrast(0.2),\n",
    "    RandomBrightness(0.2),\n",
    "])"
   ],
   "id": "25bc7ace927ae20b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "35bb4de9d35fd58a"
   },
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "You can experiment with different hyperparameters such as learning rates, batch sizes, and optimizers to improve the model's performance. Try changing the values in the cell below and observe how they affect the training process and final accuracy."
   ],
   "id": "35bb4de9d35fd58a"
  },
  {
   "metadata": {
    "id": "42af4176d79d2bed"
   },
   "cell_type": "code",
   "source": [
    "from keras.optimizers import Adam, SGD, RMSprop, Adagrad\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "image_size = (224, 224) # Can be increased up to 480x480\n",
    "optimizer = Adam(learning_rate=learning_rate)"
   ],
   "id": "42af4176d79d2bed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "d15650ee02f8a4b3"
   },
   "cell_type": "markdown",
   "source": [
    "## Model Architecture\n",
    "\n",
    "We used MobileNetV2 in this lab, but there are many other pre-trained models available in `tf.keras.applications` that you can experiment with. Using the cell below you can load and fine-tune models like `ResNet50`, `InceptionV3`, and more."
   ],
   "id": "d15650ee02f8a4b3"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e3675edf8e614d8",
    "outputId": "e1aedb76-fb40-4dab-f71b-0a94b6b63df9"
   },
   "cell_type": "code",
   "source": [
    "from keras.applications import MobileNetV2, ResNet50, InceptionV3\n",
    "\n",
    "# base_model = MobileNetV2(\n",
    "#     input_shape=image_size + (3,),\n",
    "#     include_top=False,\n",
    "#     weights='imagenet'\n",
    "# )\n",
    "#\n",
    "# base_model = ResNet50(\n",
    "#     input_shape=image_size + (3,),\n",
    "#     include_top=False,\n",
    "#     weights='imagenet'\n",
    "# )\n",
    "\n",
    "base_model = InceptionV3(\n",
    "    input_shape=image_size + (3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")"
   ],
   "id": "7e3675edf8e614d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "8a41f88ffa50d868"
   },
   "cell_type": "markdown",
   "source": [
    "# Fine-Tuning\n",
    "\n",
    "You can experiment with fine-tuning the pre-trained model by unfreezing some of the base layers and training them along with the top layers. Try unfreezing different blocks of layers and observe how it affects the model's performance."
   ],
   "id": "8a41f88ffa50d868"
  },
  {
   "metadata": {
    "id": "e1c941eee0aaacf7"
   },
   "cell_type": "code",
   "source": [
    "# Unfreeze the base layers\n",
    "base_model.trainable = True\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False"
   ],
   "id": "e1c941eee0aaacf7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 911
    },
    "id": "345449e52ab1312f",
    "outputId": "91763f27-d54a-4253-f394-38371ac1dd92"
   },
   "cell_type": "code",
   "source": [
    "# Rescale pixel values to [0, 1]\n",
    "rescaling = Rescaling(1.0 / 255)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Input(shape=image_size + (3,)),\n",
    "    data_augmentation,    # Apply data augmentation\n",
    "    rescaling,            # Rescale pixel values\n",
    "    base_model,           # Pre-trained base model\n",
    "    GlobalAveragePooling2D(),  # Global average pooling\n",
    "    Dense(128, activation='relu'),  # Fully connected layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Prefetch the datasets for optimized performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=15,\n",
    "    validation_data=val_dataset\n",
    ")\n"
   ],
   "id": "345449e52ab1312f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "fdd9479d01ef850d"
   },
   "cell_type": "code",
   "source": [],
   "id": "fdd9479d01ef850d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
