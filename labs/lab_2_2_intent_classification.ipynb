{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# AI Workshop - Lab 2-2: Intent Classification\n",
    "\n",
    "In this lab, we'll build a model to classify customer intents from text messages. We'll use the Hugging Face Transformers library to fine-tune a pre-trained model on a dataset of customer messages and intents."
   ],
   "id": "89800ddaafaa2296"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install -Uq datasets transformers accelerate evaluate",
   "id": "3d3c731f7713c24a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "from datasets import load_dataset",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "intents = load_dataset(\"parquet\", data_files={\"train\": \"data/customer_intent_train.parquet\", \"test\": \"data/customer_intent_test.parquet\"})",
   "id": "7d83bae93beee534",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "intents['train']",
   "id": "299346eb1c241001",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "api.create_repo(repo_id=\"alexwaolson/customer-intents\", repo_type=\"dataset\")"
   ],
   "id": "d42e663bd70dfdaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "intents.push_to_hub(\"alexwaolson/customer-intents\")",
   "id": "be88b28b4f6d7864",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(intents['train']['label'])"
   ],
   "id": "4b11c9f3d9801d3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load our tokenizer\n",
    "model_name = 't5-small'\n",
    "# The AutoTokenizer class will automatically select the correct tokenizer class for the model!\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "id": "c1d73e9530267d08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tokenizer('Hello, how are you?')",
   "id": "4e29ee94454c7eb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def show_tokenization(tokenizer, text):\n",
    "    print(f'Original text: {text}')\n",
    "    tokens = tokenizer(text, truncation=True)['input_ids']\n",
    "    for token in tokens:\n",
    "        print(f'{tokenizer.decode([token]):10} -> {token}')\n",
    "\n",
    "# Write any sentence and see how it gets tokenized by the model:\n",
    "show_tokenization(tokenizer, 'your sentence here')"
   ],
   "id": "33041b43d6be5ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"message\"], truncation=True)"
   ],
   "id": "fffa6578628279e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tokenized_intents = intents.map(preprocess_function, batched=True)",
   "id": "46a2ba13951d2fcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tokenized_intents['train']",
   "id": "1c5fbcf9894aee67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
   ],
   "id": "24864c6472656092",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ],
   "id": "bcb2ca52ef98dd4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # Unpack the predictions and labels\n",
    "    predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "\n",
    "    # Handle tuple predictions\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]  # Take the first element, assuming it's the logits\n",
    "\n",
    "    # Convert to NumPy array if necessary\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Compute class predictions\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Return computed metrics\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n"
   ],
   "id": "d2d1cb5dca0d2ea9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert labels to integers\n",
    "label2id = {label: i for i, label in enumerate(intents['train'].unique('label'))}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "def encode_label(example):\n",
    "    example['label'] = label2id[example['label']]\n",
    "    return example\n",
    "\n",
    "tokenized_intents = tokenized_intents.map(encode_label)"
   ],
   "id": "b76a3c69846fb5b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tokenized_intents['train']",
   "id": "600bb1d54469c32b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"t5-small\",\n",
    "    num_labels=27,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ],
   "id": "af740a75def25f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    save_steps=10,\n",
    "    output_dir='model',\n",
    "    overwrite_output_dir=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_intents['train'],\n",
    "    eval_dataset=tokenized_intents['test'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "id": "473c1e3c017258a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "e0d9f665319dec61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "efa96b1127d5636e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
